{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "health_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "7Xf0q1MFjytl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(df, test_size=0.2):\n",
        "  return sklearn.model_selection.train_test_split(df, test_size=test_size)"
      ],
      "metadata": {
        "id": "1HO1pvmcyalJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Food_Supply_Quantity_kg_Data.csv')"
      ],
      "metadata": {
        "id": "3sISgXCykC-F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = df.dropna()"
      ],
      "metadata": {
        "id": "0WVBvP5XkxHa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "xZXm6fqe0Ve_",
        "outputId": "bcd5350d-d00f-4364-c7cd-2aacd1d0dccf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8c4425a4-b581-49d6-9ab9-753a0df43ee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Alcoholic Beverages</th>\n",
              "      <th>Animal fats</th>\n",
              "      <th>Animal Products</th>\n",
              "      <th>Aquatic Products, Other</th>\n",
              "      <th>Cereals - Excluding Beer</th>\n",
              "      <th>Eggs</th>\n",
              "      <th>Fish, Seafood</th>\n",
              "      <th>Fruits - Excluding Wine</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Milk - Excluding Butter</th>\n",
              "      <th>Miscellaneous</th>\n",
              "      <th>Offals</th>\n",
              "      <th>Oilcrops</th>\n",
              "      <th>Pulses</th>\n",
              "      <th>Spices</th>\n",
              "      <th>Starchy Roots</th>\n",
              "      <th>Stimulants</th>\n",
              "      <th>Sugar &amp; Sweeteners</th>\n",
              "      <th>Sugar Crops</th>\n",
              "      <th>Treenuts</th>\n",
              "      <th>Vegetable Oils</th>\n",
              "      <th>Vegetables</th>\n",
              "      <th>Vegetal Products</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>Undernourished</th>\n",
              "      <th>Confirmed</th>\n",
              "      <th>Deaths</th>\n",
              "      <th>Recovered</th>\n",
              "      <th>Active</th>\n",
              "      <th>Population</th>\n",
              "      <th>Unit (all except Population)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.1973</td>\n",
              "      <td>9.4341</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>24.8097</td>\n",
              "      <td>0.2099</td>\n",
              "      <td>0.0350</td>\n",
              "      <td>5.3495</td>\n",
              "      <td>1.2020</td>\n",
              "      <td>7.5828</td>\n",
              "      <td>0.0728</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>0.2953</td>\n",
              "      <td>0.0574</td>\n",
              "      <td>0.8802</td>\n",
              "      <td>0.3078</td>\n",
              "      <td>1.3489</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0770</td>\n",
              "      <td>0.5345</td>\n",
              "      <td>6.7642</td>\n",
              "      <td>40.5645</td>\n",
              "      <td>4.5</td>\n",
              "      <td>29.8</td>\n",
              "      <td>0.142134</td>\n",
              "      <td>0.006186</td>\n",
              "      <td>0.123374</td>\n",
              "      <td>0.012574</td>\n",
              "      <td>38928000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Albania</td>\n",
              "      <td>1.6719</td>\n",
              "      <td>0.1357</td>\n",
              "      <td>18.7684</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5.7817</td>\n",
              "      <td>0.5815</td>\n",
              "      <td>0.2126</td>\n",
              "      <td>6.7861</td>\n",
              "      <td>1.8845</td>\n",
              "      <td>15.7213</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.2324</td>\n",
              "      <td>0.9377</td>\n",
              "      <td>0.2380</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>1.8096</td>\n",
              "      <td>0.1055</td>\n",
              "      <td>1.5367</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1515</td>\n",
              "      <td>0.3261</td>\n",
              "      <td>11.7753</td>\n",
              "      <td>31.2304</td>\n",
              "      <td>22.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>2.967301</td>\n",
              "      <td>0.050951</td>\n",
              "      <td>1.792636</td>\n",
              "      <td>1.123714</td>\n",
              "      <td>2838000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Algeria</td>\n",
              "      <td>0.2711</td>\n",
              "      <td>0.0282</td>\n",
              "      <td>9.6334</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>13.6816</td>\n",
              "      <td>0.5277</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>6.3801</td>\n",
              "      <td>1.1305</td>\n",
              "      <td>7.6189</td>\n",
              "      <td>0.1671</td>\n",
              "      <td>0.0870</td>\n",
              "      <td>0.3493</td>\n",
              "      <td>0.4783</td>\n",
              "      <td>0.0557</td>\n",
              "      <td>4.1340</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>1.8342</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1152</td>\n",
              "      <td>1.0310</td>\n",
              "      <td>11.6484</td>\n",
              "      <td>40.3651</td>\n",
              "      <td>26.6</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.244897</td>\n",
              "      <td>0.006558</td>\n",
              "      <td>0.167572</td>\n",
              "      <td>0.070767</td>\n",
              "      <td>44357000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Angola</td>\n",
              "      <td>5.8087</td>\n",
              "      <td>0.0560</td>\n",
              "      <td>4.9278</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>9.1085</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>1.7707</td>\n",
              "      <td>6.0005</td>\n",
              "      <td>2.0571</td>\n",
              "      <td>0.8311</td>\n",
              "      <td>0.1165</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>0.4186</td>\n",
              "      <td>0.6507</td>\n",
              "      <td>0.0009</td>\n",
              "      <td>18.1102</td>\n",
              "      <td>0.0508</td>\n",
              "      <td>1.8495</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.6463</td>\n",
              "      <td>2.3041</td>\n",
              "      <td>45.0722</td>\n",
              "      <td>6.8</td>\n",
              "      <td>25</td>\n",
              "      <td>0.061687</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.056808</td>\n",
              "      <td>0.003419</td>\n",
              "      <td>32522000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>4.2672</td>\n",
              "      <td>0.2234</td>\n",
              "      <td>19.3454</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8.4102</td>\n",
              "      <td>0.9979</td>\n",
              "      <td>0.4693</td>\n",
              "      <td>6.0435</td>\n",
              "      <td>7.0421</td>\n",
              "      <td>10.2328</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3779</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0122</td>\n",
              "      <td>3.0420</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>3.0536</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.9541</td>\n",
              "      <td>4.3503</td>\n",
              "      <td>30.6559</td>\n",
              "      <td>28.5</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.356147</td>\n",
              "      <td>0.108227</td>\n",
              "      <td>3.905192</td>\n",
              "      <td>0.342729</td>\n",
              "      <td>45377000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Armenia</td>\n",
              "      <td>0.4014</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>13.5640</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>7.2982</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.2896</td>\n",
              "      <td>6.0989</td>\n",
              "      <td>2.2675</td>\n",
              "      <td>9.9407</td>\n",
              "      <td>0.2355</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.0899</td>\n",
              "      <td>0.1441</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>2.0359</td>\n",
              "      <td>0.1863</td>\n",
              "      <td>2.6579</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1108</td>\n",
              "      <td>0.4705</td>\n",
              "      <td>16.7019</td>\n",
              "      <td>36.4358</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.3</td>\n",
              "      <td>5.681225</td>\n",
              "      <td>0.105345</td>\n",
              "      <td>5.398410</td>\n",
              "      <td>0.177470</td>\n",
              "      <td>2956000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Australia</td>\n",
              "      <td>5.5436</td>\n",
              "      <td>0.3143</td>\n",
              "      <td>21.4175</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>5.4979</td>\n",
              "      <td>0.4428</td>\n",
              "      <td>1.4264</td>\n",
              "      <td>4.1883</td>\n",
              "      <td>6.7049</td>\n",
              "      <td>12.1018</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.4240</td>\n",
              "      <td>0.3694</td>\n",
              "      <td>0.0546</td>\n",
              "      <td>0.0458</td>\n",
              "      <td>2.7884</td>\n",
              "      <td>0.2928</td>\n",
              "      <td>2.5364</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3176</td>\n",
              "      <td>1.2798</td>\n",
              "      <td>5.1406</td>\n",
              "      <td>28.5806</td>\n",
              "      <td>30.4</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>0.112025</td>\n",
              "      <td>0.003530</td>\n",
              "      <td>0.101289</td>\n",
              "      <td>0.007207</td>\n",
              "      <td>25754000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Austria</td>\n",
              "      <td>7.0215</td>\n",
              "      <td>0.8555</td>\n",
              "      <td>19.5654</td>\n",
              "      <td>0.0011</td>\n",
              "      <td>6.2116</td>\n",
              "      <td>0.7884</td>\n",
              "      <td>0.7562</td>\n",
              "      <td>4.6069</td>\n",
              "      <td>4.6810</td>\n",
              "      <td>12.3776</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.1052</td>\n",
              "      <td>0.2683</td>\n",
              "      <td>0.0456</td>\n",
              "      <td>0.0494</td>\n",
              "      <td>3.0548</td>\n",
              "      <td>0.4106</td>\n",
              "      <td>2.6094</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2367</td>\n",
              "      <td>0.8109</td>\n",
              "      <td>5.1098</td>\n",
              "      <td>30.4338</td>\n",
              "      <td>21.9</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>4.739982</td>\n",
              "      <td>0.089679</td>\n",
              "      <td>4.496870</td>\n",
              "      <td>0.153433</td>\n",
              "      <td>8914000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Azerbaijan</td>\n",
              "      <td>3.5969</td>\n",
              "      <td>0.2544</td>\n",
              "      <td>11.6416</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>13.0898</td>\n",
              "      <td>0.5593</td>\n",
              "      <td>0.2020</td>\n",
              "      <td>4.7988</td>\n",
              "      <td>2.1513</td>\n",
              "      <td>8.3212</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.1534</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.0347</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>4.7041</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>1.5523</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1906</td>\n",
              "      <td>0.2235</td>\n",
              "      <td>10.0755</td>\n",
              "      <td>38.3584</td>\n",
              "      <td>19.9</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>2.285536</td>\n",
              "      <td>0.031223</td>\n",
              "      <td>2.225574</td>\n",
              "      <td>0.028740</td>\n",
              "      <td>10108000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bangladesh</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>5.1926</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>29.8045</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>2.5221</td>\n",
              "      <td>2.8655</td>\n",
              "      <td>0.4191</td>\n",
              "      <td>1.8778</td>\n",
              "      <td>0.0197</td>\n",
              "      <td>0.0633</td>\n",
              "      <td>0.0820</td>\n",
              "      <td>0.7065</td>\n",
              "      <td>0.3195</td>\n",
              "      <td>5.3378</td>\n",
              "      <td>0.0529</td>\n",
              "      <td>0.9285</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>0.0934</td>\n",
              "      <td>0.7615</td>\n",
              "      <td>3.6405</td>\n",
              "      <td>44.8033</td>\n",
              "      <td>3.4</td>\n",
              "      <td>14.7</td>\n",
              "      <td>0.316691</td>\n",
              "      <td>0.004823</td>\n",
              "      <td>0.284344</td>\n",
              "      <td>0.027524</td>\n",
              "      <td>169809000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Barbados</td>\n",
              "      <td>3.5650</td>\n",
              "      <td>0.2212</td>\n",
              "      <td>12.4976</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8.0666</td>\n",
              "      <td>0.7792</td>\n",
              "      <td>3.2750</td>\n",
              "      <td>5.8723</td>\n",
              "      <td>5.8477</td>\n",
              "      <td>2.2041</td>\n",
              "      <td>3.3020</td>\n",
              "      <td>0.1704</td>\n",
              "      <td>0.8734</td>\n",
              "      <td>0.6391</td>\n",
              "      <td>0.1565</td>\n",
              "      <td>4.0812</td>\n",
              "      <td>0.1721</td>\n",
              "      <td>4.3344</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0852</td>\n",
              "      <td>0.8677</td>\n",
              "      <td>5.4725</td>\n",
              "      <td>37.5167</td>\n",
              "      <td>24.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.583972</td>\n",
              "      <td>0.006272</td>\n",
              "      <td>0.470035</td>\n",
              "      <td>0.107666</td>\n",
              "      <td>287000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Belarus</td>\n",
              "      <td>3.7563</td>\n",
              "      <td>0.3353</td>\n",
              "      <td>12.7089</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>6.2814</td>\n",
              "      <td>0.7565</td>\n",
              "      <td>0.8372</td>\n",
              "      <td>3.5665</td>\n",
              "      <td>4.1893</td>\n",
              "      <td>6.2104</td>\n",
              "      <td>0.5035</td>\n",
              "      <td>0.3795</td>\n",
              "      <td>0.0720</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>9.1691</td>\n",
              "      <td>0.1142</td>\n",
              "      <td>4.0155</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1399</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>8.7859</td>\n",
              "      <td>37.2904</td>\n",
              "      <td>26.6</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>2.740896</td>\n",
              "      <td>0.018912</td>\n",
              "      <td>2.612704</td>\n",
              "      <td>0.109280</td>\n",
              "      <td>9375000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Belgium</td>\n",
              "      <td>5.3730</td>\n",
              "      <td>0.8559</td>\n",
              "      <td>17.7279</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>6.6704</td>\n",
              "      <td>0.6487</td>\n",
              "      <td>1.1325</td>\n",
              "      <td>4.1623</td>\n",
              "      <td>3.2370</td>\n",
              "      <td>11.6344</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2185</td>\n",
              "      <td>0.0965</td>\n",
              "      <td>0.1132</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>4.4157</td>\n",
              "      <td>0.2461</td>\n",
              "      <td>3.6514</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1309</td>\n",
              "      <td>0.5640</td>\n",
              "      <td>6.8161</td>\n",
              "      <td>32.2637</td>\n",
              "      <td>24.5</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>6.286322</td>\n",
              "      <td>0.185428</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.100894</td>\n",
              "      <td>11515000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Belize</td>\n",
              "      <td>3.3803</td>\n",
              "      <td>0.0832</td>\n",
              "      <td>8.6856</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>11.0700</td>\n",
              "      <td>0.3923</td>\n",
              "      <td>1.0325</td>\n",
              "      <td>12.6094</td>\n",
              "      <td>3.4890</td>\n",
              "      <td>3.6317</td>\n",
              "      <td>1.7653</td>\n",
              "      <td>0.0569</td>\n",
              "      <td>0.3940</td>\n",
              "      <td>1.1259</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>1.0614</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>3.9798</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0340</td>\n",
              "      <td>1.0198</td>\n",
              "      <td>4.7721</td>\n",
              "      <td>41.3122</td>\n",
              "      <td>22.4</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2.872792</td>\n",
              "      <td>0.073031</td>\n",
              "      <td>2.739618</td>\n",
              "      <td>0.060143</td>\n",
              "      <td>419000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Benin</td>\n",
              "      <td>5.9019</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>3.7504</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>9.6230</td>\n",
              "      <td>0.0711</td>\n",
              "      <td>1.2267</td>\n",
              "      <td>2.9523</td>\n",
              "      <td>1.4107</td>\n",
              "      <td>0.9458</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.0829</td>\n",
              "      <td>0.6628</td>\n",
              "      <td>0.7367</td>\n",
              "      <td>0.4461</td>\n",
              "      <td>19.7771</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.6635</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4028</td>\n",
              "      <td>0.7381</td>\n",
              "      <td>4.1964</td>\n",
              "      <td>46.2493</td>\n",
              "      <td>8.2</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0.034344</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.029183</td>\n",
              "      <td>0.004710</td>\n",
              "      <td>12209000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Bolivia</td>\n",
              "      <td>2.8956</td>\n",
              "      <td>0.0889</td>\n",
              "      <td>11.7799</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>12.3079</td>\n",
              "      <td>0.6626</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>7.5088</td>\n",
              "      <td>6.4098</td>\n",
              "      <td>4.2873</td>\n",
              "      <td>0.1661</td>\n",
              "      <td>0.1006</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.0422</td>\n",
              "      <td>7.7315</td>\n",
              "      <td>0.2083</td>\n",
              "      <td>2.5724</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7084</td>\n",
              "      <td>0.3573</td>\n",
              "      <td>3.2224</td>\n",
              "      <td>38.2165</td>\n",
              "      <td>18.7</td>\n",
              "      <td>17.1</td>\n",
              "      <td>1.952446</td>\n",
              "      <td>0.092435</td>\n",
              "      <td>1.438614</td>\n",
              "      <td>0.421396</td>\n",
              "      <td>11633000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Bosnia and Herzegovina</td>\n",
              "      <td>4.7876</td>\n",
              "      <td>0.0585</td>\n",
              "      <td>12.4319</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8.7152</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.2465</td>\n",
              "      <td>4.6409</td>\n",
              "      <td>1.8165</td>\n",
              "      <td>9.9443</td>\n",
              "      <td>0.4860</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.0963</td>\n",
              "      <td>0.2718</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>4.0495</td>\n",
              "      <td>0.3504</td>\n",
              "      <td>1.6391</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0822</td>\n",
              "      <td>0.4205</td>\n",
              "      <td>11.6394</td>\n",
              "      <td>37.5645</td>\n",
              "      <td>19.4</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>3.762085</td>\n",
              "      <td>0.145535</td>\n",
              "      <td>2.960317</td>\n",
              "      <td>0.656233</td>\n",
              "      <td>3281000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Botswana</td>\n",
              "      <td>4.2717</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>14.4486</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>11.4320</td>\n",
              "      <td>0.1402</td>\n",
              "      <td>0.3551</td>\n",
              "      <td>2.8465</td>\n",
              "      <td>2.2840</td>\n",
              "      <td>11.0217</td>\n",
              "      <td>1.6092</td>\n",
              "      <td>0.3056</td>\n",
              "      <td>0.2019</td>\n",
              "      <td>0.2729</td>\n",
              "      <td>0.1626</td>\n",
              "      <td>4.7614</td>\n",
              "      <td>0.1336</td>\n",
              "      <td>4.7857</td>\n",
              "      <td>0.0009</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>1.0065</td>\n",
              "      <td>4.0558</td>\n",
              "      <td>35.5491</td>\n",
              "      <td>16.1</td>\n",
              "      <td>26.4</td>\n",
              "      <td>1.014372</td>\n",
              "      <td>0.007035</td>\n",
              "      <td>0.844799</td>\n",
              "      <td>0.162538</td>\n",
              "      <td>2317000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Brazil</td>\n",
              "      <td>4.3629</td>\n",
              "      <td>0.2803</td>\n",
              "      <td>17.3470</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8.4292</td>\n",
              "      <td>0.5042</td>\n",
              "      <td>0.5899</td>\n",
              "      <td>6.0936</td>\n",
              "      <td>6.4784</td>\n",
              "      <td>9.3416</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.7093</td>\n",
              "      <td>0.9254</td>\n",
              "      <td>0.0071</td>\n",
              "      <td>3.3959</td>\n",
              "      <td>0.3024</td>\n",
              "      <td>2.7755</td>\n",
              "      <td>1.0111</td>\n",
              "      <td>0.0513</td>\n",
              "      <td>1.2823</td>\n",
              "      <td>3.3070</td>\n",
              "      <td>32.6537</td>\n",
              "      <td>22.3</td>\n",
              "      <td>&lt;2.5</td>\n",
              "      <td>4.460165</td>\n",
              "      <td>0.108603</td>\n",
              "      <td>3.979469</td>\n",
              "      <td>0.372094</td>\n",
              "      <td>211812000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Bulgaria</td>\n",
              "      <td>7.0834</td>\n",
              "      <td>0.2488</td>\n",
              "      <td>17.2483</td>\n",
              "      <td>0.0103</td>\n",
              "      <td>8.8750</td>\n",
              "      <td>0.5924</td>\n",
              "      <td>0.4845</td>\n",
              "      <td>3.9812</td>\n",
              "      <td>4.0073</td>\n",
              "      <td>11.5992</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>0.3058</td>\n",
              "      <td>0.3450</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.6048</td>\n",
              "      <td>1.8576</td>\n",
              "      <td>0.2818</td>\n",
              "      <td>2.3627</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0797</td>\n",
              "      <td>0.7085</td>\n",
              "      <td>6.2037</td>\n",
              "      <td>32.7435</td>\n",
              "      <td>27.4</td>\n",
              "      <td>3.6</td>\n",
              "      <td>3.227256</td>\n",
              "      <td>0.134416</td>\n",
              "      <td>2.788956</td>\n",
              "      <td>0.303883</td>\n",
              "      <td>6927000.0</td>\n",
              "      <td>%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c4425a4-b581-49d6-9ab9-753a0df43ee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c4425a4-b581-49d6-9ab9-753a0df43ee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c4425a4-b581-49d6-9ab9-753a0df43ee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   Country  ...  Unit (all except Population)\n",
              "0              Afghanistan  ...                             %\n",
              "1                  Albania  ...                             %\n",
              "2                  Algeria  ...                             %\n",
              "3                   Angola  ...                             %\n",
              "5                Argentina  ...                             %\n",
              "6                  Armenia  ...                             %\n",
              "7                Australia  ...                             %\n",
              "8                  Austria  ...                             %\n",
              "9               Azerbaijan  ...                             %\n",
              "11              Bangladesh  ...                             %\n",
              "12                Barbados  ...                             %\n",
              "13                 Belarus  ...                             %\n",
              "14                 Belgium  ...                             %\n",
              "15                  Belize  ...                             %\n",
              "16                   Benin  ...                             %\n",
              "17                 Bolivia  ...                             %\n",
              "18  Bosnia and Herzegovina  ...                             %\n",
              "19                Botswana  ...                             %\n",
              "20                  Brazil  ...                             %\n",
              "21                Bulgaria  ...                             %\n",
              "\n",
              "[20 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avrages = clean_df.mean()\n",
        "avrages[avrages > 3].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIbH6mCf0Prm",
        "outputId": "20f65ab1-df54-43cc-9164-9ff724c9fc94"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Alcoholic Beverages                3\n",
              "Animal Products                   12\n",
              "Cereals - Excluding Beer          12\n",
              "Fruits - Excluding Wine            5\n",
              "Meat                               3\n",
              "Milk - Excluding Butter            6\n",
              "Starchy Roots                      5\n",
              "Vegetables                         5\n",
              "Vegetal Products                  37\n",
              "Obesity                           18\n",
              "Population                  47965785\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_cols = [\"Alcoholic Beverages\", \"Animal Products\", \"Cereals - Excluding Beer\", \"Fruits - Excluding Wine\", \"Milk - Excluding Butter\", \"Starchy Roots\", \"Vegetal Products\", \"Obesity\"]\n",
        "relevant_df = clean_df[relevant_cols]"
      ],
      "metadata": {
        "id": "eUKvPb3y0JoC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_renames = [\"Alcohol\", \"Meat\", \"Cereals\", \"Fruits\", \"Milk\", \"Starchy Roots\", \"Vegetable\", \"Obesity\"]\n",
        "relevant_df.columns = column_renames"
      ],
      "metadata": {
        "id": "2eO1lIGE2Jgg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo21FKkG2Cr4",
        "outputId": "0f9d900e-8740-4302-d910-9f2582dca907"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 154 entries, 0 to 169\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Alcohol        154 non-null    float64\n",
            " 1   Meat           154 non-null    float64\n",
            " 2   Cereals        154 non-null    float64\n",
            " 3   Fruits         154 non-null    float64\n",
            " 4   Milk           154 non-null    float64\n",
            " 5   Starchy Roots  154 non-null    float64\n",
            " 6   Vegetable      154 non-null    float64\n",
            " 7   Obesity        154 non-null    float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 10.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avrages = relevant_df.mean()\n",
        "avrages[avrages > 3].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr1ZPHvS4A4R",
        "outputId": "9b10e1c4-0ecd-427b-8f3f-82dda58ca89c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Alcohol           3\n",
              "Meat             12\n",
              "Cereals          12\n",
              "Fruits            5\n",
              "Milk              6\n",
              "Starchy Roots     5\n",
              "Vegetable        37\n",
              "Obesety          18\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_df = relevant_df[\"Obesity\"]\n",
        "X_df = relevant_df.drop([\"Obesity\"], axis=1)"
      ],
      "metadata": {
        "id": "wDn3KwZ84jwX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_values = np.array(y_df.values).astype(np.float32)\n",
        "X_values = np.array(X_df.values).astype(np.float32)"
      ],
      "metadata": {
        "id": "s2vY7roj5IiZ"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tensors = torch.from_numpy(y_values).to(device)\n",
        "X_tensors = torch.from_numpy(X_values).to(device)"
      ],
      "metadata": {
        "id": "YHL8OeIiHepf"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_tensors[10:]\n",
        "y_test = y_tensors[:10]\n",
        "X_train = X_tensors[10:]\n",
        "X_test = X_tensors[:10]"
      ],
      "metadata": {
        "id": "4YD97PYa5TEF"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a3tRAwL6l3B",
        "outputId": "ff1f7970-c918-4ae5-e759-ffc512d7dd89"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fetech_req = [\n",
        "    {\n",
        "      \"id\": 5,\n",
        "      \"amount_g\": 11000.0,\n",
        "      \"category\": \"Bagels and English muffins\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 10,\n",
        "      \"amount_g\": 30.0,\n",
        "      \"category\": \"Candy containing chocolate\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 46,\n",
        "      \"amount_g\": 102.600003,\n",
        "      \"category\": \"Chicken whole pieces\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 4,\n",
        "      \"amount_g\": 4.0,\n",
        "      \"category\": \"Coffee\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 50,\n",
        "      \"amount_g\": 525.599976,\n",
        "      \"category\": \"Cold cuts and cured meats\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 42,\n",
        "      \"amount_g\": 100.0,\n",
        "      \"category\": \"Cream and cream substitutes\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 52,\n",
        "      \"amount_g\": 262.799988,\n",
        "      \"category\": \"Not included in a food category\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 44,\n",
        "      \"amount_g\": 78.780003,\n",
        "      \"category\": \"Other starchy vegetables\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 48,\n",
        "      \"amount_g\": 929.599976,\n",
        "      \"category\": \"Rice mixed dishes\"\n",
        "    }\n",
        "  ]"
      ],
      "metadata": {
        "id": "ZsBmJyI-uPes"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "K6alnXETm6Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bGKblqUPmUoN",
        "outputId": "50008a8a-a52d-442f-d6f2-088e902be715"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(7, 64),\n",
        "        self.fc2 = nn.Linear(64, 64),\n",
        "        self.fc3 = nn.Linear(64, 1),\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.flatten(x)\n",
        "        x = F.relu(self.fc1)\n",
        "        x = F.relu(self.fc2)\n",
        "        x = self.fc3\n",
        "        return F.log_softmax(x, dim=1)\n",
        "net = NeuralNetwork().to(device)\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THMWSEnzn132",
        "outputId": "b0e95a6f-aca9-4a04-c75b-34997d79ea74"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=7, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(X_train)\n",
        "len(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_AX3PlYpVKf",
        "outputId": "52a3a00d-fd1d-4a27-f1ae-e71d1edcfe28"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([144, 7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = NeuralNetwork().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "EPOCHS = 3\n",
        "for epoch in range(EPOCHS):\n",
        "  for i in range(len(X_train)):\n",
        "    X = X_train[i]\n",
        "    y = y_train[i]\n",
        "    net.zero_grad()\n",
        "    output = net(X)\n",
        "    loss = loss_fn(output, y)\n",
        "    loss = F.l1_loss(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMvTIrYguJ-Z",
        "outputId": "eee9ae47-830a-4aa3-8b16-b1c0b94a7a73"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "tensor(2.9132, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "tensor(0.9457, device='cuda:0', grad_fn=<L1LossBackward0>)\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "tensor(0.1841, device='cuda:0', grad_fn=<L1LossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranges = []\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(len(X_test)):\n",
        "    X = X_test[i]\n",
        "    y = y_test[i]\n",
        "    output = net(X)\n",
        "    ranges.append(abs(y-output[0]))\n",
        "print(f\"Avrage range: {sum(ranges)/len(ranges)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFaVpkgAF18i",
        "outputId": "991fdab2-08a5-448c-9844-775abca32bc4"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "Avrage range: 4.929542064666748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"/content/model_state.pt\")"
      ],
      "metadata": {
        "id": "Eb-4cA-UF2xK"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net, \"/content/model.pt\")"
      ],
      "metadata": {
        "id": "6FyzsnvvF29C"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_net = torch.load(\"/content/model.pt\")\n",
        "\n",
        "ranges = []\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(len(X_test)):\n",
        "    X = X_test[i]\n",
        "    y = y_test[i]\n",
        "    output = new_net(X)\n",
        "    ranges.append(abs(y-output[0]))\n",
        "print(f\"Avrage range: {sum(ranges)/len(ranges)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vfljcrYRsjf",
        "outputId": "4e54807c-87c8-4126-a866-7fa7d517bdd2"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "torch.Size([7])\n",
            "Avrage range: 4.929542064666748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nSZ20qV0SJvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}